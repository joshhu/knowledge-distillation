{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# çŸ¥è­˜è’¸é¤¾ï¼ˆKnowledge Distillationï¼‰å®Œæ•´æ•™å­¸\n",
    "\n",
    "æœ¬æ•™å­¸å°‡å±•ç¤ºå¦‚ä½•ä½¿ç”¨çŸ¥è­˜è’¸é¤¾æŠ€è¡“ï¼Œå°‡å¤§å‹æ•™å¸«æ¨¡å‹çš„çŸ¥è­˜è½‰ç§»åˆ°å°å‹å­¸ç”Ÿæ¨¡å‹ã€‚\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/joshhu/knowledge-distillation/blob/main/notebooks/knowledge_distillation_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ä»€éº¼æ˜¯çŸ¥è­˜è’¸é¤¾ï¼Ÿ\n",
    "\n",
    "çŸ¥è­˜è’¸é¤¾æ˜¯ä¸€ç¨®æ¨¡å‹å£“ç¸®æŠ€è¡“ï¼š\n",
    "\n",
    "- **æ•™å¸«æ¨¡å‹**ï¼šå¤§å‹ã€é«˜æ•ˆèƒ½çš„æ¨¡å‹ï¼ˆå¦‚ ResNet18ï¼‰\n",
    "- **å­¸ç”Ÿæ¨¡å‹**ï¼šå°å‹ã€è¼•é‡çš„æ¨¡å‹\n",
    "- **è»Ÿæ¨™ç±¤**ï¼šæ•™å¸«æ¨¡å‹è¼¸å‡ºçš„æ©Ÿç‡åˆ†ä½ˆ\n",
    "- **æº«åº¦åƒæ•¸**ï¼šæ§åˆ¶è»Ÿæ¨™ç±¤çš„å¹³æ»‘ç¨‹åº¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 1: ç’°å¢ƒè¨­å®š\n",
    "\n",
    "å®‰è£å¿…è¦çš„å¥—ä»¶ä¸¦ clone å°ˆæ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£ä¾è³´å¥—ä»¶\n",
    "!pip install -q torch torchvision tqdm matplotlib\n",
    "\n",
    "# Clone å°ˆæ¡ˆ\n",
    "!git clone https://github.com/joshhu/knowledge-distillation.git\n",
    "%cd knowledge-distillation\n",
    "\n",
    "print(\"âœ“ ç’°å¢ƒè¨­å®šå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 2: åŒ¯å…¥å¿…è¦çš„æ¨¡çµ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from data import get_cifar10_dataloaders\n",
    "from models import TeacherModel, StudentModel\n",
    "from distillation import DistillationLoss, DistillationTrainer\n",
    "from utils import set_seed, plot_training_curves, compare_models\n",
    "\n",
    "# æª¢æŸ¥ GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ä½¿ç”¨è£ç½®: {device}')\n",
    "\n",
    "# è¨­å®šéš¨æ©Ÿç¨®å­\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 3: è¼‰å…¥ CIFAR-10 è³‡æ–™é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_cifar10_dataloaders(\n",
    "    data_dir='./data',\n",
    "    batch_size=128,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"è³‡æ–™é›†: CIFAR-10\")\n",
    "print(f\"é¡åˆ¥æ•¸é‡: 10\")\n",
    "print(f\"è¨“ç·´æ¨£æœ¬: 50000\")\n",
    "print(f\"æ¸¬è©¦æ¨£æœ¬: 10000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 4: å»ºç«‹æ•™å¸«æ¨¡å‹å’Œå­¸ç”Ÿæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = TeacherModel(num_classes=10).to(device)\n",
    "student_model = StudentModel(num_classes=10).to(device)\n",
    "\n",
    "print(\"æ¨¡å‹å»ºç«‹å®Œæˆï¼\")\n",
    "compare_models(teacher_model, student_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 5: è¨“ç·´æ•™å¸«æ¨¡å‹\n",
    "\n",
    "æ³¨æ„ï¼šç‚ºäº†ç¤ºç¯„ï¼Œé€™è£¡åªè¨“ç·´å°‘é‡ epochsã€‚å¯¦éš›æ‡‰ç”¨å»ºè­°è¨“ç·´ 20-50 epochsã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_teacher(model, train_loader, test_loader, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    best_acc = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        test_acc = 100. * correct / total\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch}: æ¸¬è©¦æº–ç¢ºç‡ = {test_acc:.2f}%')\n",
    "        \n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "    \n",
    "    print(f'æ•™å¸«æ¨¡å‹æœ€ä½³æº–ç¢ºç‡: {best_acc:.2f}%')\n",
    "    return model\n",
    "\n",
    "# è¨“ç·´æ•™å¸«æ¨¡å‹ï¼ˆè¨­ç‚º 5 epochs å¿«é€Ÿç¤ºç¯„ï¼Œå¯¦éš›å»ºè­° 20+ï¼‰\n",
    "teacher_model = train_teacher(teacher_model, train_loader, test_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 6: é…ç½®çŸ¥è­˜è’¸é¤¾åƒæ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 3.0\n",
    "alpha = 0.7\n",
    "num_epochs = 10  # ç¤ºç¯„ç”¨ï¼Œå¯¦éš›å»ºè­° 50+\n",
    "\n",
    "distillation_loss = DistillationLoss(temperature=temperature, alpha=alpha)\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    student_model.parameters(),\n",
    "    lr=0.1,\n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "trainer = DistillationTrainer(\n",
    "    teacher_model=teacher_model,\n",
    "    student_model=student_model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    distillation_loss=distillation_loss,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "print(f\"çŸ¥è­˜è’¸é¤¾é…ç½®ï¼š\")\n",
    "print(f\"  æº«åº¦åƒæ•¸: {temperature}\")\n",
    "print(f\"  Alpha: {alpha}\")\n",
    "print(f\"  è¨“ç·´è¼ªæ•¸: {num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 7: é–‹å§‹çŸ¥è­˜è’¸é¤¾è¨“ç·´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.train(num_epochs=num_epochs)\n",
    "\n",
    "torch.save(student_model.state_dict(), 'student_model_distilled.pth')\n",
    "print(\"å­¸ç”Ÿæ¨¡å‹å·²å„²å­˜ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 8: è¦–è¦ºåŒ–è¨“ç·´çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥é©Ÿ 9: æ•ˆèƒ½æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return 100. * correct / total\n",
    "\n",
    "teacher_acc = evaluate_model(teacher_model, test_loader, device)\n",
    "student_acc = evaluate_model(student_model, test_loader, device)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"æœ€çµ‚æ•ˆèƒ½æ¯”è¼ƒ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"æ•™å¸«æ¨¡å‹æº–ç¢ºç‡: {teacher_acc:.2f}%\")\n",
    "print(f\"å­¸ç”Ÿæ¨¡å‹æº–ç¢ºç‡: {student_acc:.2f}%\")\n",
    "print(f\"æ•ˆèƒ½ä¿ç•™ç‡: {100 * student_acc / teacher_acc:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ç¸½çµ\n",
    "\n",
    "æ­å–œï¼ä½ å·²ç¶“å®Œæˆäº†çŸ¥è­˜è’¸é¤¾çš„å®Œæ•´æµç¨‹ï¼š\n",
    "\n",
    "1. âœ… è¼‰å…¥ä¸¦é è™•ç†è³‡æ–™\n",
    "2. âœ… å»ºç«‹æ•™å¸«å’Œå­¸ç”Ÿæ¨¡å‹\n",
    "3. âœ… è¨“ç·´æ•™å¸«æ¨¡å‹\n",
    "4. âœ… é…ç½®çŸ¥è­˜è’¸é¤¾\n",
    "5. âœ… è¨“ç·´å­¸ç”Ÿæ¨¡å‹\n",
    "6. âœ… è©•ä¼°å’Œæ¯”è¼ƒæ•ˆèƒ½\n",
    "\n",
    "## ğŸš€ é€²éšç·´ç¿’\n",
    "\n",
    "1. èª¿æ•´æº«åº¦åƒæ•¸ï¼ˆè©¦è©¦ 1.0, 5.0, 10.0ï¼‰\n",
    "2. èª¿æ•´ alpha å€¼ï¼ˆè©¦è©¦ 0.5, 0.8, 0.9ï¼‰\n",
    "3. å¢åŠ è¨“ç·´è¼ªæ•¸åˆ° 50-100 epochs\n",
    "4. å˜—è©¦ä¸åŒçš„æ¨¡å‹æ¶æ§‹\n",
    "\n",
    "## ğŸ“š åƒè€ƒè³‡æ–™\n",
    "\n",
    "- [åŸå§‹è«–æ–‡](https://arxiv.org/abs/1503.02531) - Hinton et al., 2015\n",
    "- [å°ˆæ¡ˆ GitHub](https://github.com/joshhu/knowledge-distillation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}