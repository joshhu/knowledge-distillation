"""
çŸ¥è­˜è’¸é¤¾è¨“ç·´å™¨
ç®¡ç†æ•´å€‹è¨“ç·´å’Œè©•ä¼°æµç¨‹
"""
import torch
import torch.nn as nn
from tqdm import tqdm
import time


class DistillationTrainer:
    """
    çŸ¥è­˜è’¸é¤¾è¨“ç·´å™¨
    è² è²¬è¨“ç·´å­¸ç”Ÿæ¨¡å‹ï¼Œä½¿ç”¨æ•™å¸«æ¨¡å‹çš„çŸ¥è­˜
    """
    def __init__(
        self,
        teacher_model,
        student_model,
        train_loader,
        test_loader,
        distillation_loss,
        optimizer,
        device='cuda',
        scheduler=None
    ):
        """
        åˆå§‹åŒ–è¨“ç·´å™¨

        åƒæ•¸:
            teacher_model: æ•™å¸«æ¨¡å‹ï¼ˆå·²è¨“ç·´å¥½ï¼‰
            student_model: å­¸ç”Ÿæ¨¡å‹ï¼ˆå¾…è¨“ç·´ï¼‰
            train_loader: è¨“ç·´è³‡æ–™è¼‰å…¥å™¨
            test_loader: æ¸¬è©¦è³‡æ–™è¼‰å…¥å™¨
            distillation_loss: è’¸é¤¾æå¤±å‡½æ•¸
            optimizer: å„ªåŒ–å™¨
            device: é‹ç®—è£ç½®
            scheduler: å­¸ç¿’ç‡èª¿æ•´å™¨ï¼ˆå¯é¸ï¼‰
        """
        self.teacher_model = teacher_model.to(device)
        self.student_model = student_model.to(device)
        self.train_loader = train_loader
        self.test_loader = test_loader
        self.distillation_loss = distillation_loss
        self.optimizer = optimizer
        self.device = device
        self.scheduler = scheduler

        # å°‡æ•™å¸«æ¨¡å‹è¨­ç‚ºè©•ä¼°æ¨¡å¼
        self.teacher_model.eval()
        for param in self.teacher_model.parameters():
            param.requires_grad = False

        # è¨“ç·´æ­·å²è¨˜éŒ„
        self.history = {
            'train_loss': [],
            'train_acc': [],
            'test_loss': [],
            'test_acc': [],
            'distillation_loss': [],
            'student_loss': []
        }

    def train_epoch(self, epoch):
        """
        è¨“ç·´ä¸€å€‹ epoch

        åƒæ•¸:
            epoch: ç•¶å‰ epoch æ•¸

        å›å‚³:
            avg_loss: å¹³å‡æå¤±
            avg_acc: å¹³å‡æº–ç¢ºç‡
            avg_dist_loss: å¹³å‡è’¸é¤¾æå¤±
            avg_student_loss: å¹³å‡å­¸ç”Ÿæå¤±
        """
        self.student_model.train()

        total_loss = 0
        total_dist_loss = 0
        total_student_loss = 0
        correct = 0
        total = 0

        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}')
        for batch_idx, (inputs, targets) in enumerate(pbar):
            inputs, targets = inputs.to(self.device), targets.to(self.device)

            # å–å¾—æ•™å¸«æ¨¡å‹çš„è¼¸å‡ºï¼ˆä¸éœ€è¦æ¢¯åº¦ï¼‰
            with torch.no_grad():
                teacher_logits = self.teacher_model(inputs)

            # å–å¾—å­¸ç”Ÿæ¨¡å‹çš„è¼¸å‡º
            student_logits = self.student_model(inputs)

            # è¨ˆç®—æå¤±
            loss, dist_loss, student_loss = self.distillation_loss(
                student_logits, teacher_logits, targets
            )

            # åå‘å‚³æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            # çµ±è¨ˆ
            total_loss += loss.item()
            total_dist_loss += dist_loss.item()
            total_student_loss += student_loss.item()

            _, predicted = student_logits.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

            # æ›´æ–°é€²åº¦æ¢
            pbar.set_postfix({
                'Loss': f'{loss.item():.3f}',
                'Acc': f'{100.*correct/total:.2f}%'
            })

        avg_loss = total_loss / len(self.train_loader)
        avg_dist_loss = total_dist_loss / len(self.train_loader)
        avg_student_loss = total_student_loss / len(self.train_loader)
        avg_acc = 100. * correct / total

        return avg_loss, avg_acc, avg_dist_loss, avg_student_loss

    def evaluate(self):
        """
        è©•ä¼°æ¨¡å‹åœ¨æ¸¬è©¦é›†ä¸Šçš„è¡¨ç¾

        å›å‚³:
            avg_loss: å¹³å‡æå¤±
            avg_acc: å¹³å‡æº–ç¢ºç‡
        """
        self.student_model.eval()
        total_loss = 0
        correct = 0
        total = 0

        criterion = nn.CrossEntropyLoss()

        with torch.no_grad():
            for inputs, targets in self.test_loader:
                inputs, targets = inputs.to(self.device), targets.to(self.device)

                outputs = self.student_model(inputs)
                loss = criterion(outputs, targets)

                total_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()

        avg_loss = total_loss / len(self.test_loader)
        avg_acc = 100. * correct / total

        return avg_loss, avg_acc

    def train(self, num_epochs):
        """
        åŸ·è¡Œå®Œæ•´çš„è¨“ç·´æµç¨‹

        åƒæ•¸:
            num_epochs: è¨“ç·´çš„ epoch æ•¸é‡

        å›å‚³:
            history: è¨“ç·´æ­·å²è¨˜éŒ„
        """
        print("=" * 70)
        print("é–‹å§‹çŸ¥è­˜è’¸é¤¾è¨“ç·´")
        print("=" * 70)

        best_acc = 0
        start_time = time.time()

        for epoch in range(1, num_epochs + 1):
            # è¨“ç·´
            train_loss, train_acc, dist_loss, student_loss = self.train_epoch(epoch)

            # è©•ä¼°
            test_loss, test_acc = self.evaluate()

            # æ›´æ–°å­¸ç¿’ç‡
            if self.scheduler is not None:
                self.scheduler.step()

            # è¨˜éŒ„æ­·å²
            self.history['train_loss'].append(train_loss)
            self.history['train_acc'].append(train_acc)
            self.history['test_loss'].append(test_loss)
            self.history['test_acc'].append(test_acc)
            self.history['distillation_loss'].append(dist_loss)
            self.history['student_loss'].append(student_loss)

            # è¼¸å‡ºçµæœ
            print(f'\nEpoch: {epoch}/{num_epochs}')
            print(f'è¨“ç·´ - æå¤±: {train_loss:.4f}, æº–ç¢ºç‡: {train_acc:.2f}%')
            print(f'æ¸¬è©¦ - æå¤±: {test_loss:.4f}, æº–ç¢ºç‡: {test_acc:.2f}%')
            print(f'è’¸é¤¾æå¤±: {dist_loss:.4f}, å­¸ç”Ÿæå¤±: {student_loss:.4f}')

            # å„²å­˜æœ€ä½³æ¨¡å‹
            if test_acc > best_acc:
                best_acc = test_acc
                print(f'ğŸ¯ æ–°çš„æœ€ä½³æº–ç¢ºç‡: {best_acc:.2f}%')

            print("-" * 70)

        elapsed_time = time.time() - start_time
        print(f"\nè¨“ç·´å®Œæˆ! ç¸½è€—æ™‚: {elapsed_time/60:.2f} åˆ†é˜")
        print(f"æœ€ä½³æ¸¬è©¦æº–ç¢ºç‡: {best_acc:.2f}%")

        return self.history

    def get_history(self):
        """
        å–å¾—è¨“ç·´æ­·å²è¨˜éŒ„

        å›å‚³:
            history: è¨“ç·´æ­·å²å­—å…¸
        """
        return self.history
